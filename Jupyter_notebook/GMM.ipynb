{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import scipy\n",
    "import numpy \n",
    "import matplotlib.pyplot as plt\n",
    "from scipy import linalg, special, stats\n",
    "from numpy import genfromtxt\n",
    "import ML_support as ml\n",
    "from scipy.optimize import fmin_l_bfgs_b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "Data, labels = ml.loadFile('../Train.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_g = ml.gaussianize(Data)\n",
    "data_z = ml.z_normalization(Data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def full_GMM(DTR, LTR, DTE, n_repetions):\n",
    "    N = DTR.shape[1]\n",
    "    t = 1e-6\n",
    "    w = 1.0\n",
    "    alpha = 0.1\n",
    "    final_scores = {}\n",
    "    gmm = {}\n",
    "    \n",
    "    mu, C = ml.MU_Cov_calculator(DTR, LTR)\n",
    "    \n",
    "    for i in numpy.unique(LTR):\n",
    "        gmm[i] = [w, mu[i], C[i]]\n",
    "        GMM_final = {0 : gmm[i]}\n",
    "        \n",
    "        for j in range (n_repetions):\n",
    "            GMM_init = GMM_final.copy()\n",
    "            \n",
    "            for k, g in enumerate(GMM_init.values()):\n",
    "                w, mu, Cov = g\n",
    "                newW = w/2\n",
    "                U, s, Vh = numpy.linalg.svd(Cov)\n",
    "                d = U[:, 0:1]*s[0]**0.5*alpha\n",
    "                newMu1 = mu+d\n",
    "                newMu2 = mu-d\n",
    "                GMM_final[k*2] = [newW, newMu1, Cov]\n",
    "                GMM_final[k*2+1] = [newW, newMu2, Cov]\n",
    "                \n",
    "            GMM_final, opt_ll = ml.optimize_GMM(DTE, GMM_final)\n",
    "        final_scores[i] = opt_ll\n",
    "    \n",
    "    r = final_scores[1]-final_scores[0]\n",
    "    \n",
    "    return list(r[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def kfold(D, L, fold, params, app):\n",
    "    error = 0\n",
    "    N = int(D.shape[1]/fold) #numero di elementi per ogni fold\n",
    "    numpy.random.seed(0) #imposto il seed del generatore di numeri casuali -> in tal modo genererò la stessa sequenza di numeri casuali aventi seed uguale\n",
    "    indexes = numpy.random.permutation(D.shape[1]) #genero una sequenza di numeri casuali che vanno da 0 al num_di_campioni\n",
    "    \n",
    "    LTE_final = []\n",
    "    llr_final = []\n",
    "    for j in range(fold):\n",
    "        test_indexes = indexes[(j*N):((j+1)*N)] #selezioni gli indici che identificano i campioni (casuali) del test set\n",
    "        if(j > 0): #se il test set non è preso dalla prima fold (--> il test set è una fold intermedia o l'ultima fold)\n",
    "            left_indexes = indexes[0:(j*N)] #allora prendo tutti gli indici che stanno a sinistra di tale fold\n",
    "        else: #se il test set è preso dalla prima fold\n",
    "            right_indexes = indexes[((j+1)*N):] #prendo tutti gli indici a destra della prima fold\n",
    "\n",
    "        if(j == 0): #se il test set è preso dalla prima fold\n",
    "            train_indexes = right_indexes #assegno agli indici di training quelli che stanno a destra della prima fold\n",
    "        elif(j == fold-1): #se il test set è preso dall'ultima fold\n",
    "            train_indexes = left_indexes #assegno agli indici di training quelli che stanno a sinistra dell'ultima fold\n",
    "        else: #in questo caso il test set è preso da una fold intermedia\n",
    "            train_indexes = numpy.hstack((left_indexes, right_indexes)) #pertanto assegno agli indici di training quelli appartenenti alle fold di sinistra e di destra\n",
    "\n",
    "        DTR = D[:, train_indexes]  #definisco insieme di training e di testing\n",
    "        LTR = L[train_indexes]\n",
    "        DTE = D[:, test_indexes]\n",
    "        LTE = L[test_indexes]\n",
    "        LTE_final.extend(LTE)\n",
    "        llr_final.extend(full_GMM(DTR, LTR, DTE, params))\n",
    "    \n",
    "    \n",
    "    CM = ml.compute_optimal_B_decision(app, llr_final, LTE_final)\n",
    "\n",
    "    app_bayes_risk=ml.compute_Bayes_risk(CM, app)\n",
    "    DCF = ml.compute_norm_Bayes(app_bayes_risk, app)\n",
    "    \n",
    "    minDCF, _= ml.compute_min_DCF(llr_final, app, LTE_final)\n",
    "    \n",
    "    error = 1-(CM[0, 0]+CM[1,1])/(len(LTE_final))\n",
    "\n",
    "    print(\"\\-/ \\-/ \\-/ \\-/ \\-/ \")\n",
    "    print(f\"GMM error: {round(error, 3)}\")\n",
    "    print(f'{app} DCF:{round(DCF, 3)} minDCF: {round(minDCF,3)}')\n",
    "    print(\"/-\\ /-\\ /-\\ /-\\ /-\\ \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\\-/ \\-/ \\-/ \\-/ \\-/ \n",
      "GMM error: 0.207\n",
      "[0.5, 1, 1] DCF:0.313 minDCF: 0.291\n",
      "/-\\ /-\\ /-\\ /-\\ /-\\ \n"
     ]
    }
   ],
   "source": [
    "kfold(Data, labels, 5, 2, [0.5, 1, 1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
