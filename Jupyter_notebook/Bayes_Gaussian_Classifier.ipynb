{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import scipy\n",
    "import numpy \n",
    "import matplotlib.pyplot as plt\n",
    "from scipy import linalg, special, stats\n",
    "from numpy import genfromtxt\n",
    "import ML_support as ml"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BayesClassifier:\n",
    "    def __init__(self):\n",
    "        self.C = {}\n",
    "        self.mu = {}\n",
    "        \n",
    "    def train(self, DTR, LTR):\n",
    "\n",
    "        self.mu, self.C = ml.MU_Cov_calculator(DTR, LTR)\n",
    "        for i in numpy.unique(LTR):\n",
    "            self.C[i] *= numpy.eye(self.C[i].shape[0])\n",
    "\n",
    "    def test(self, DTE, LTE):\n",
    "\n",
    "        S = numpy.zeros((numpy.unique(LTE).size, DTE.shape[1]))\n",
    "        predicted = []\n",
    "\n",
    "        for i in numpy.unique(LTE):\n",
    "            S[i, :] =ml.GAU_logpdf_ND(DTE, self.mu[i], self.C[i])  + numpy.log(1/2)\n",
    "\n",
    "        Sp = scipy.special.logsumexp(S, axis=0)\n",
    "\n",
    "        for x, p in zip(S.T, Sp):\n",
    "            tmp = x - p\n",
    "            predicted.append(numpy.argmax(tmp))\n",
    "\n",
    "        predicted = numpy.array(predicted)\n",
    "       \n",
    "        True_prediction = numpy.array([predicted == LTE])\n",
    "        error = 1 - (numpy.count_nonzero(True_prediction) / True_prediction.size)\n",
    "        print(\"Bayes Classifier error:\", error)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "Data, label = ml.loadFile('../Train.txt')\n",
    "(DTR, LTR), (DTE,LTE) = ml.split_db_2to1(Data, label, seed=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bayes Classifier error: 0.06315082297615049\n"
     ]
    }
   ],
   "source": [
    "G=BayesClassifier()\n",
    "G.train(DTR,LTR)\n",
    "G.test(DTE,LTE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bayes Classifier error: 0.41182398387638564\n",
      "Bayes Classifier error: 0.06348673160900231\n"
     ]
    }
   ],
   "source": [
    "Gn=BayesClassifier()\n",
    "Gn.train(ml.z_normalization(DTR), LTR)\n",
    "Gn.test(DTE, LTE)\n",
    "Gn.test(ml.z_normalization(DTE), LTE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bayes Classifier error: 0.0923748740342627\n",
      "Bayes Classifier error: 0.05844810211622442\n"
     ]
    }
   ],
   "source": [
    "GG=BayesClassifier()\n",
    "GG.train(ml.gaussianize(DTR), LTR)\n",
    "GG.test(DTE, LTE)\n",
    "GG.test(ml.gaussianize(DTE), LTE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BayesClassifier_mod1:\n",
    "    def __init__(self):\n",
    "        self.C = {}\n",
    "        self.mu = {}\n",
    "        \n",
    "    def train(self, DTR, LTR):\n",
    "\n",
    "        self.mu, self.C = ml.MU_Cov_calculator(DTR, LTR)\n",
    "        for i in numpy.unique(LTR):\n",
    "            self.C[i] *= numpy.eye(self.C[i].shape[0])\n",
    "\n",
    "    def test(self, DTE, LTE, app, ROC=False):\n",
    "        \n",
    "        S = numpy.zeros((numpy.unique(LTE).size, DTE.shape[1]))\n",
    "        ll=numpy.zeros((numpy.unique(LTE).size, DTE.shape[1]))\n",
    "        predicted = []\n",
    "\n",
    "        for i in numpy.unique(LTE):\n",
    "            ll[i, :]=ml.GAU_logpdf_ND(DTE, self.mu[i], self.C[i])\n",
    "       \n",
    "        llr = numpy.array(ll[1, :]-ll[0, :])\n",
    "        \n",
    "        CM = ml.compute_optimal_B_decision(app, llr, LTE)\n",
    "        sensitivity = (1-ml.compute_FNR(CM)) # TPR\n",
    "        specificity = (1-ml.compute_FPR(CM)) # TNR\n",
    "        \n",
    "        app_bayes_risk=ml.compute_Bayes_risk(CM, app)\n",
    "        DCF = ml.compute_norm_Bayes(app_bayes_risk, app)\n",
    "        \n",
    "        minDCF= ml.compute_min_DCF(llr, app, LTE)\n",
    "        error = 1-(CM[0, 0]+CM[1,1])/(len(LTE))\n",
    "        if(ROC == True):\n",
    "            ml.plot_ROC(app, llr, LTE)\n",
    "        \n",
    "        print(\"\\-/ \\-/ \\-/ \\-/ \\-/ \")\n",
    "        print(\"Gaussian Classifier error:\", error)\n",
    "        print(app,\"DCF:\", DCF, \"minDCF:\", minDCF)\n",
    "        print('Sensitivity (TPR):', sensitivity, ' Specificity (TNR): ', specificity)\n",
    "        print('CM\\n', CM)\n",
    "        print(\"/-\\ /-\\ /-\\ /-\\ /-\\ \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\\-/ \\-/ \\-/ \\-/ \\-/ \n",
      "Gaussian Classifier error: 0.06315082297615049\n",
      "[0.5, 1, 1] DCF: 0.1936962519345939 minDCF: 0.19141107597066145\n",
      "Sensitivity (TPR): 0.8618181818181818  Specificity (TNR):  0.9444855662472242\n",
      "CM\n",
      " [[2552.   38.]\n",
      " [ 150.  237.]]\n",
      "/-\\ /-\\ /-\\ /-\\ /-\\ \n"
     ]
    }
   ],
   "source": [
    "G=BayesClassifier_mod1()\n",
    "G.train(DTR,LTR)\n",
    "G.test(DTE,LTE, [1/2,1,1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\\-/ \\-/ \\-/ \\-/ \\-/ \n",
      "Gaussian Classifier error: 0.054417198522002\n",
      "[0.1, 1, 1] DCF: 0.552431195747258 minDCF: 0.3123921674180742\n",
      "Sensitivity (TPR): 0.8472727272727273  Specificity (TNR):  0.9555884529977794\n",
      "CM\n",
      " [[2582.   42.]\n",
      " [ 120.  233.]]\n",
      "/-\\ /-\\ /-\\ /-\\ /-\\ \n"
     ]
    }
   ],
   "source": [
    "G.test(DTE,LTE, [0.1, 1, 1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\\-/ \\-/ \\-/ \\-/ \\-/ \n",
      "Gaussian Classifier error: 0.07423580786026196\n",
      "[0.9, 1, 1] DCF: 1.2142924433079876 minDCF: 0.6069591548348026\n",
      "Sensitivity (TPR): 0.8727272727272728  Specificity (TNR):  0.9311621021465581\n",
      "CM\n",
      " [[2516.   35.]\n",
      " [ 186.  240.]]\n",
      "/-\\ /-\\ /-\\ /-\\ /-\\ \n"
     ]
    }
   ],
   "source": [
    "G.test(DTE,LTE, [0.9, 1, 1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BayesClassifier_mod2:\n",
    "    def __init__(self):\n",
    "        self.C = {}\n",
    "        self.mu = {}\n",
    "        \n",
    "    def train(self, DTR, LTR):\n",
    "\n",
    "        self.mu, self.C = ml.MU_Cov_calculator(DTR, LTR)\n",
    "        for i in numpy.unique(LTR):\n",
    "            self.C[i] *= numpy.eye(self.C[i].shape[0])\n",
    "\n",
    "    def test(self, DTE, LTE):\n",
    "        \n",
    "        S = numpy.zeros((numpy.unique(LTE).size, DTE.shape[1]))\n",
    "        ll=numpy.zeros((numpy.unique(LTE).size, DTE.shape[1]))\n",
    "        predicted = []\n",
    "\n",
    "        for i in numpy.unique(LTE):\n",
    "            ll[i, :]=ml.GAU_logpdf_ND(DTE, self.mu[i], self.C[i])\n",
    "       \n",
    "        return list(ll[1, :]-ll[0, :])\n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def kfold(classifier, D, L, fold, app):\n",
    "    error = 0\n",
    "    N = int(D.shape[1]/fold) #numero di elementi per ogni fold\n",
    "    numpy.random.seed(0) #imposto il seed del generatore di numeri casuali -> in tal modo genererò la stessa sequenza di numeri casuali aventi seed uguale\n",
    "    indexes = numpy.random.permutation(D.shape[1]) #genero una sequenza di numeri casuali che vanno da 0 al num_di_campioni\n",
    "    \n",
    "    LTE_final = []\n",
    "    llr_final = []\n",
    "    for j in range(fold):\n",
    "        test_indexes = indexes[(j*N):((j+1)*N)] #selezioni gli indici che identificano i campioni (casuali) del test set\n",
    "        if(j > 0): #se il test set non è preso dalla prima fold (--> il test set è una fold intermedia o l'ultima fold)\n",
    "            left_indexes = indexes[0:(j*N)] #allora prendo tutti gli indici che stanno a sinistra di tale fold\n",
    "        else: #se il test set è preso dalla prima fold\n",
    "            right_indexes = indexes[((j+1)*N):] #prendo tutti gli indici a destra della prima fold\n",
    "\n",
    "        if(j == 0): #se il test set è preso dalla prima fold\n",
    "            train_indexes = right_indexes #assegno agli indici di training quelli che stanno a destra della prima fold\n",
    "        elif(j == fold-1): #se il test set è preso dall'ultima fold\n",
    "            train_indexes = left_indexes #assegno agli indici di training quelli che stanno a sinistra dell'ultima fold\n",
    "        else: #in questo caso il test set è preso da una fold intermedia\n",
    "            train_indexes = numpy.hstack((left_indexes, right_indexes)) #pertanto assegno agli indici di training quelli appartenenti alle fold di sinistra e di destra\n",
    "\n",
    "        DTR = D[:, train_indexes]  #definisco insieme di training e di testing\n",
    "        LTR = L[train_indexes]\n",
    "        DTE = D[:, test_indexes]\n",
    "        LTE = L[test_indexes]\n",
    "        LTE_final.extend(LTE)\n",
    "        classifier.train(DTR, LTR)\n",
    "        llr_final.extend(classifier.test(DTE, LTE))\n",
    "        \n",
    "    CM = ml.compute_optimal_B_decision(app, llr_final, LTE_final)\n",
    "    sensitivity = (1-ml.compute_FNR(CM)) # TPR\n",
    "    specificity = (1-ml.compute_FPR(CM)) # TNR\n",
    "        \n",
    "    app_bayes_risk=ml.compute_Bayes_risk(CM, app)\n",
    "    DCF = ml.compute_norm_Bayes(app_bayes_risk, app)\n",
    "\n",
    "    minDCF= ml.compute_min_DCF(llr_final, app, LTE_final)\n",
    "    error = 1-(CM[0, 0]+CM[1,1])/(len(LTE_final))\n",
    "\n",
    "    print(\"\\-/ \\-/ \\-/ \\-/ \\-/ \")\n",
    "    print(\"Gaussian Classifier error:\", error)\n",
    "    print(app,\"DCF:\", DCF, \"minDCF:\", minDCF)\n",
    "    print('Sensitivity (TPR):', sensitivity, ' Specificity (TNR): ', specificity)\n",
    "    print('CM\\n', CM)\n",
    "    print(\"/-\\ /-\\ /-\\ /-\\ /-\\ \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "kg = BayesClassifier_mod2()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "d_g = ml.gaussianize(Data)\n",
    "d_z = ml.z_normalization(Data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\\-/ \\-/ \\-/ \\-/ \\-/ \n",
      "Gaussian Classifier error: 0.061960784313725537\n",
      "[0.5, 1, 1] DCF: 0.19412046561569268 minDCF: 0.1930258346730025\n",
      "Sensitivity (TPR): 0.8599269183922047  Specificity (TNR):  0.9459526159921027\n",
      "CM\n",
      " [[7666.  115.]\n",
      " [ 438.  706.]]\n",
      "/-\\ /-\\ /-\\ /-\\ /-\\ \n"
     ]
    }
   ],
   "source": [
    "kfold(kg, Data, label, 5, [0.5, 1, 1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\\-/ \\-/ \\-/ \\-/ \\-/ \n",
      "Gaussian Classifier error: 0.056918767507002754\n",
      "[0.5, 1, 1] DCF: 0.15791798579489774 minDCF: 0.15197905306532736\n",
      "Sensitivity (TPR): 0.8940316686967114  Specificity (TNR):  0.948050345508391\n",
      "CM\n",
      " [[7683.   87.]\n",
      " [ 421.  734.]]\n",
      "/-\\ /-\\ /-\\ /-\\ /-\\ \n"
     ]
    }
   ],
   "source": [
    "kfold(kg, d_g, label, 5, [0.5, 1, 1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\\-/ \\-/ \\-/ \\-/ \\-/ \n",
      "Gaussian Classifier error: 0.061960784313725537\n",
      "[0.5, 1, 1] DCF: 0.19412046561569268 minDCF: 0.1930258346730025\n",
      "Sensitivity (TPR): 0.8599269183922047  Specificity (TNR):  0.9459526159921027\n",
      "CM\n",
      " [[7666.  115.]\n",
      " [ 438.  706.]]\n",
      "/-\\ /-\\ /-\\ /-\\ /-\\ \n"
     ]
    }
   ],
   "source": [
    "kfold(kg, d_z, label, 5, [0.5, 1, 1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
